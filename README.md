# Sonic World Events Bot\n\nA Telegram bot designed to help manage Luma events via natural language commands, powered by Google Gemini.\n\n## Overview\n\nThis bot acts as an AI assistant or secretary, allowing users to interact with their Luma account to:\n*   List upcoming events\n*   Get details about specific events\n*   List guests for events (with filters like pending/approved)\n*   Approve or decline pending guests\n\n## Development Philosophy: Simplify Code, Trust Gemini, Post-Process\n\nThis project follows these core principles:\n\n1.  **Simplify Code:** Minimize intermediate steps, routing logic, and state management in the Javascript code.\n2.  **Trust Gemini's Reasoning:** Rely on a primary Gemini call to understand user intent, determine the necessary action (direct answer vs. tool call), and generate direct answers or tool specifications.\n3.  **Post-Process for Presentation:** Use a dedicated, final post-processing step (another Gemini call) to ensure the output text meets the desired conversational tone and minimal Markdown requirements for Telegram.\n\nThis approach prioritizes leveraging the LLM's capabilities and separating core logic from final presentation refinement.\n\nSee `BOT_CAPABILITIES.md` for a more detailed breakdown of features, limitations, and how the bot works.\n\n## Essential Implementation Notes\n\n### Google Gemini Integration\n\nThe bot uses the latest `@google/genai` package (version 0.10.0+). Here's the correct way to implement Gemini:\n\n```javascript\nconst { GoogleGenAI } = require('@google/genai');\n\n// Initialize with API key\nconst genAI = new GoogleGenAI({ apiKey: process.env.GEMINI_API_KEY });\n\n// Generate content\nconst result = await genAI.models.generateContent({
  model: "gemini-1.5-flash", // or your preferred model
  contents: [{ role: "user", parts: [{ text: prompt }] }]
});
\n\n// Get response text\nconst responseText = result.text;\n```\n\nKey points:\n- Use `GoogleGenAI` constructor with `{ apiKey: ... }` format\n- Use `genAI.models.generateContent()` instead of getting a model first\n- Access response text via `result.text` (not `result.response.text()`)\n- Always wrap in try/catch for error handling\n\n## Setup\n\n1.  **Deploy:** Deploy the bot (e.g., to Heroku). Ensure environment variables like `BOT_TOKEN`, `GEMINI_API_KEY`, and `ENCRYPTION_KEY` are set.\n2.  **Link Luma Account:** Start a **Direct Message (DM)** with the deployed bot in Telegram. Use the `/link` command and follow the prompts to provide your Luma API key securely. This authorizes the bot to access your Luma data.\n\n## Usage\n\nInteract with the bot in Telegram using natural language:\n*   \"What events are coming up?\"\n*   \"Tell me about the Dubai event.\"\n*   \"Show pending guests for the Vienna summit.\"\n*   \"How many people are approved for evt-...\"\n*   \"Approve guest@example.com for the Dubai event.\"\n*   \"Decline test@test.com for evt-...\"\n\nThe bot will determine the required action, interact with the Luma API if necessary, and provide a response.\n\n## Contributing\n\n(Add contribution guidelines if applicable)\n\n## License\n\n(Add license information if applicable)\n